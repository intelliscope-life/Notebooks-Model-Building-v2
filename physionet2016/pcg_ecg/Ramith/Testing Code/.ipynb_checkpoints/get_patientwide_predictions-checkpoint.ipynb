{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Instantiating Session without specifying a backend is deprecated and will be removed in future versions. For current behaviour use `neptune.init(...)` or `Session.with_default_backend(...)\n",
      "WARNING: There is a new version of neptune-client 0.4.125 (installed: 0.4.124).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total  707\n",
      "199 Images loaded across 2 Categories. Ignored blanks  60\n",
      "508 Images loaded across 2 Categories. Ignored blanks  9\n",
      "638 Total After removing blanks\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ubuntu/intelliscope/modules')\n",
    "\n",
    "#!pip install neptune-client\n",
    "import os\n",
    "import neptune\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Lambda,BatchNormalization\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Lambda\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "\n",
    "from intelliscope import instead_data_loaders\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from neptunecontrib.monitoring.metrics import *\n",
    "from neptune.sessions import Session\n",
    "import custom_metrics\n",
    "\n",
    "\n",
    "################################################################################################################\n",
    "project_name='Patientwise-Test-HYBRID-Imbalanced'\n",
    "prev_project_name='HYBRID-Imbalanced'\n",
    "TrainTestVal='test'\n",
    "################################################################################################################\n",
    "\n",
    "\n",
    "NEPTUNE_API_TOKEN='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5haSIsImFwaV91cmwiOiJodHRwczovL3VpLm5lcHR1bmUuYWkiLCJhcGlfa2V5IjoiMzc1YTM5OGMtYTY3Ny00ZmM4LTg5ZGQtOGI2YTQ1YmZiMDkzIn0='\n",
    "session = Session(api_token=NEPTUNE_API_TOKEN)\n",
    "\n",
    "project = session.get_projects('intelliscope')['intelliscope/'+prev_project_name]\n",
    "experiments=project.get_experiments()\n",
    "X_test,Y_test,names = instead_data_loaders(experiments[0].get_parameters(),TrainTestVal, True) # because we have separate projects for balanced, imbalanced datasets\n",
    "\n",
    "\n",
    "def get_results(model=None, X_test_pcg=None, X_test_ecg=None, Y_test=None, threshold = 0.5):    \n",
    "    y_pred = model.predict([X_test_pcg,X_test_ecg], batch_size=32, verbose=1)\n",
    "    y_test = np.argmax(Y_test,axis=1)\n",
    "    \n",
    "    print(custom_metrics._class_metrics(y_test, y_pred[:, 1] > threshold))\n",
    "    return y_test, y_pred\n",
    "    \n",
    "\n",
    "def neptune_log_metrics(y_test=None, y_pred=None, threshold = 0.5):\n",
    "    log_confusion_matrix(y_test, y_pred[:, 1] > threshold)\n",
    "    log_classification_report(y_test, y_pred[:, 1] > threshold)\n",
    "    log_class_metrics(y_test, y_pred[:, 1] > threshold)\n",
    "    log_class_metrics_by_threshold(y_test, y_pred[:, 1])\n",
    "    log_brier_loss(y_test, y_pred[:, 1])\n",
    "    log_prediction_distribution(y_test, y_pred[:, 1])\n",
    "\n",
    "    log_log_loss(y_test, y_pred)\n",
    "    log_roc_auc(y_test, y_pred)\n",
    "    log_precision_recall_auc(y_test, y_pred)\n",
    "    log_ks_statistic(y_test, y_pred)\n",
    "    log_cumulative_gain(y_test, y_pred)\n",
    "    log_lift_curve(y_test, y_pred)\n",
    "    \n",
    "\n",
    "\n",
    "def get_individual_metrics(y_test, y_pred, names):\n",
    "    patient_preds={}\n",
    "    for i in range(len(names)): # create dict: patient_record_name: [start_point, label, [pred0, pred1]] \n",
    "        name=names[i]\n",
    "        record_name,record_start_point,_=name.strip().split('_')\n",
    "        if record_name in patient_preds:\n",
    "            patient_preds[record_name].append([int(record_start_point),y_test[i], list(y_pred[i])])\n",
    "        else:\n",
    "            patient_preds[record_name]=[[int(record_start_point),y_test[i], list(y_pred[i])]]\n",
    "\n",
    "    y_test_bulk, y_pred_bulk=[],[]    \n",
    "    for key in patient_preds: # return :: patient-wise y_test, y_preds\n",
    "        patient_pred=patient_preds[key]\n",
    "        label, pred_label=get_single_patient_pred(patient_pred, mean)\n",
    "\n",
    "        y_test_bulk.append(label)\n",
    "        y_pred_bulk.append(pred_label)\n",
    "\n",
    "    y_test_bulk=np.array(y_test_bulk)\n",
    "    y_pred_bulk=np.array(y_pred_bulk)\n",
    "    print(custom_metrics._class_metrics(y_test_bulk, y_pred_bulk[:, 1] > 0.5))\n",
    "    \n",
    "    return y_test_bulk, y_pred_bulk\n",
    "\n",
    "def mean(list_):\n",
    "    metric=np.mean(list_)\n",
    "    return [1-metric,metric]\n",
    "\n",
    "def get_single_patient_pred(patient_pred, func):\n",
    "    #print(patient_pred)\n",
    "    patient_pred.sort()\n",
    "    \n",
    "    y=np.array(patient_pred)[:,1]\n",
    "    \n",
    "    assert y.sum()%(y.shape[0])==0\n",
    "    label=y[0] # label of the patient\n",
    "    \n",
    "    rows=[]\n",
    "    for row in sorted(patient_pred):\n",
    "        rows.append(list(row[2]))\n",
    "    rows=np.array(rows)\n",
    "\n",
    "    y_preds=np.argmax(rows, axis=1)\n",
    "    pred_label=func(y_preds)\n",
    "    return label, pred_label\n",
    "\n",
    "def neptune_log_metrics(y_test=None, y_pred=None, threshold = 0.5):\n",
    "    log_confusion_matrix(y_test, y_pred[:, 1] > threshold)\n",
    "    log_classification_report(y_test, y_pred[:, 1] > threshold)\n",
    "    log_class_metrics(y_test, y_pred[:, 1] > threshold)\n",
    "    log_class_metrics_by_threshold(y_test, y_pred[:, 1])\n",
    "    log_brier_loss(y_test, y_pred[:, 1])\n",
    "    log_prediction_distribution(y_test, y_pred[:, 1])\n",
    "\n",
    "    log_log_loss(y_test, y_pred)\n",
    "    log_roc_auc(y_test, y_pred)\n",
    "    log_precision_recall_auc(y_test, y_pred)\n",
    "    log_ks_statistic(y_test, y_pred)\n",
    "    log_cumulative_gain(y_test, y_pred)\n",
    "    log_lift_curve(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test_pcg = X_test[:,:,:,0:3]/255.0\n",
    "X_test_ecg = X_test[:,:,:,3:6]/255.0\n",
    "\n",
    "for i in range(len(experiments)):        \n",
    "    experiment    = experiments[i]\n",
    "    model_name = str(experiment)+'.h5'\n",
    "    PARAMS     = experiment.get_parameters()\n",
    "    PARAMS['tags']=PARAMS['tags'][2:-2].strip().split(\"', '\")\n",
    "    \n",
    "    model = load_model(PARAMS['modelsave_dir']+'/'+model_name)\n",
    "    y_test, y_pred=get_results(model, X_test_pcg, X_test_ecg, Y_test)\n",
    "    \n",
    "    y_test_patientwise, y_pred_patientwise=get_individual_metrics(y_test, y_pred, names)\n",
    "\n",
    "    \n",
    "    neptune.init('intelliscope/'+project_name,NEPTUNE_API_TOKEN)\n",
    "    exp = neptune.create_experiment(name=str(experiment),description=PARAMS['name'],params=PARAMS,tags=PARAMS['tags'],upload_stdout=True)\n",
    "    neptune_log_metrics(y_test_patientwise, y_pred_patientwise)\n",
    "    neptune.stop() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
