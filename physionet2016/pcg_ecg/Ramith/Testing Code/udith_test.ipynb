{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install neptune-client\n",
    "import os\n",
    "import neptune\n",
    "\n",
    "#NEPTUNE_API_TOKEN='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5haSIsImFwaV91cmwiOiJodHRwczovL3VpLm5lcHR1bmUuYWkiLCJhcGlfa2V5IjoiMzc1YTM5OGMtYTY3Ny00ZmM4LTg5ZGQtOGI2YTQ1YmZiMDkzIn0='\n",
    "#os.environ['NEPTUNE_PROJECT']=\"intelliscope/Test-HYBRID-Imbalanced\"\n",
    "#neptune.init('intelliscope/Test-HYBRID-Imbalanced',NEPTUNE_API_TOKEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'{modelsave_dir}/{str(exp)}.h5')\n",
    "neptune.log_artifact(f'{modelsave_dir}/{str(exp)}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Instantiating Session without specifying a backend is deprecated and will be removed in future versions. For current behaviour use `neptune.init(...)` or `Session.with_default_backend(...)\n",
      "WARNING: There is a new version of neptune-client 0.4.125 (installed: 0.4.124).\n"
     ]
    }
   ],
   "source": [
    "from neptune.sessions import Session\n",
    "NEPTUNE_API_TOKEN='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5haSIsImFwaV91cmwiOiJodHRwczovL3VpLm5lcHR1bmUuYWkiLCJhcGlfa2V5IjoiMzc1YTM5OGMtYTY3Ny00ZmM4LTg5ZGQtOGI2YTQ1YmZiMDkzIn0='\n",
    "session = Session(api_token=NEPTUNE_API_TOKEN)\n",
    "\n",
    "project = session.get_projects('intelliscope')['intelliscope/HYBRID-Imbalanced']\n",
    "projects=project.get_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Experiment(HYBIM-1).h5'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Lambda,BatchNormalization\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Lambda\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "\n",
    "from intelliscope import instead_data_loaders\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from neptunecontrib.monitoring.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(model, PARAMS):\n",
    "    X_test,Y_test = instead_data_loaders(PARAMS,'test')\n",
    "\n",
    "    X_test_pcg = X_test[:,:,:,0:3]/255.0\n",
    "    X_test_ecg = X_test[:,:,:,3:6]/255.0\n",
    "\n",
    "    y_pred = model.predict([X_test[:,:,:,0:3],X_test[:,:,:,3:6]], batch_size=X_test.shape[0], verbose=1)\n",
    "\n",
    "    y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "    y_test=np.argmax(Y_test,axis=1)\n",
    "\n",
    "\n",
    "def neptune_log_results(y_test=None, y_pred=None, threshold = 0.5):\n",
    "    log_confusion_matrix(y_test, y_pred[:, 1] > threshold)\n",
    "    log_classification_report(y_test, y_pred[:, 1] > threshold)\n",
    "    log_class_metrics(y_test, y_pred[:, 1] > threshold)\n",
    "    log_class_metrics_by_threshold(y_test, y_pred[:, 1])\n",
    "    log_brier_loss(y_test, y_pred[:, 1])\n",
    "    log_prediction_distribution(y_test, y_pred[:, 1])\n",
    "\n",
    "    log_log_loss(y_test, y_pred)\n",
    "    log_roc_auc(y_test, y_pred)\n",
    "    log_precision_recall_auc(y_test, y_pred)\n",
    "    log_ks_statistic(y_test, y_pred)\n",
    "    log_cumulative_gain(y_test, y_pred)\n",
    "    log_lift_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'notebook_name': 'hybrid01_imbalanced.ipynb',\n",
       " 'name': 'data_a + imbalanced => Dilated-3',\n",
       " 'description': 'Dilated Conv at first two , batch size 20 ',\n",
       " 'tags': \"['imbalanced', 'CASS', 'Plan 1', 'c5.12xlarge', 'Dilated Conv']\",\n",
       " 'data_balanced': 'False',\n",
       " 'pretrained': 'False',\n",
       " 'modelload_pcg_dir': '/home/ubuntu/intelliscope/models/Experiment(PCG-7).h5',\n",
       " 'modelload_ecg_dir': '/home/ubuntu/intelliscope/models/Experiment(ECG-1).h5',\n",
       " 'is_features_normalized': 'False',\n",
       " 'Dilation_Rate': 3.0,\n",
       " 'augmentation': 0.0,\n",
       " 'opt': '<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fa497d92c50>',\n",
       " 'dropout': 0.2,\n",
       " 'num_epochs': 10.0,\n",
       " 'wavelet': 'comb1',\n",
       " 'batch_size': 20.0,\n",
       " 'validation_split': 0.1,\n",
       " 'test_split': 0.2,\n",
       " 'dataset': 'physionet2016a',\n",
       " 'pcg/ecg': 'pcg+ecg',\n",
       " 'pcg_dir': '/home/ubuntu/intelliscope/for_dataloaders/waveletcomb1/dataA/pcg/imbalanced',\n",
       " 'ecg_dir': '/home/ubuntu/intelliscope/for_dataloaders/waveletcomb1/dataA/ecg/imbalanced',\n",
       " 'modelsave_dir': '/home/ubuntu/intelliscope/models'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for project in projects:\n",
    "    model_name=str(project)+'.h5'\n",
    "    attr=project.get_parameters()\n",
    "    \n",
    "    model=load_model(attr['modelsave_dir']+'/'+model_name)\n",
    "    \n",
    "    y_test, y_pred=get_results(model, attr)\n",
    "    neptune_log_metrics(y_test, y_pred)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "exp = neptune.create_experiment(name=PARAMS['name'],description=PARAMS['description'],params=PARAMS,upload_source_files=PARAMS['notebook_name'],tags=PARAMS['tags'],upload_stdout=True)\n",
    "\n",
    "model.summary(print_fn=lambda x: neptune.log_text('model_summary', x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
